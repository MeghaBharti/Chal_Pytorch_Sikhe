{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTjyTecW4CsNKKSNFyvgw7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeghaBharti/Chal_Pytorch_Sikhe/blob/main/Simple_NN_with_Multiple_Inputs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Network with Multiple Inputs in PyTorch\n",
        "\n",
        "## Introduction\n",
        "A **Neural Network (NN)** is a computational model that mimics the structure of the human brain to recognize patterns and make predictions. In this case, we will design a simple neural network that takes **two inputs** and produces a **single output** based on the equation:\n",
        "\n",
        "\\[\n",
        "y = 2x_1 + 3x_2 + 5\n",
        "\\]\n",
        "\n",
        "This network is an example of a **feedforward neural network** that maps input values to output values using learnable parameters (weights and biases).\n",
        "\n",
        "---\n",
        "\n",
        "## Architecture of the Neural Network\n",
        "The network consists of:\n",
        "- **Input Layer:** Takes two input features \\( x_1 \\) and \\( x_2 \\).\n",
        "- **Hidden Layer:** Three neurons with **ReLU activation** to introduce non-linearity.\n",
        "- **Output Layer:** A single neuron that gives the final prediction.\n",
        "\n",
        "### **Layers Description**\n",
        "1. **Input Layer:**\n",
        "   - Accepts two input values: \\( x_1 \\) and \\( x_2 \\).\n",
        "   \n",
        "2. **Hidden Layer:**\n",
        "   - Has **3 neurons** to process the inputs.\n",
        "   - Uses the **ReLU activation function** to introduce non-linearity.\n",
        "   \n",
        "3. **Output Layer:**\n",
        "   - A single neuron that computes the final output.\n",
        "   \n",
        "---\n",
        "\n",
        "## Learning Process\n",
        "The **neural network learns** to predict \\( y \\) by adjusting weights and biases using the **gradient descent** optimization algorithm.\n",
        "\n",
        "### **Training Steps**\n",
        "1. **Forward Pass:** The input \\( (x_1, x_2) \\) is passed through the layers to compute the predicted output.\n",
        "2. **Loss Calculation:** The error is measured using **Mean Squared Error (MSE)** loss function.\n",
        "3. **Backpropagation:** The network calculates gradients of weights and biases to reduce the loss.\n",
        "4. **Weight Update:** The optimizer updates the parameters to minimize the error.\n",
        "5. **Repeat:** Steps 1-4 are repeated for multiple epochs to improve accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Components\n",
        "- **Neurons:** Computational units that apply weights to inputs.\n",
        "- **Activation Function (ReLU):** Introduces non-linearity for better learning.\n",
        "- **Loss Function (MSE):** Measures the difference between actual and predicted output.\n",
        "- **Optimizer (SGD):** Updates weights to reduce loss over time.\n",
        "\n",
        "---\n",
        "\n",
        "## Expected Outcome\n",
        "After training, the network should learn to approximate the function:\n",
        "\n",
        "\\[\n",
        "y = 2x_1 + 3x_2 + 5\n",
        "\\]\n",
        "\n",
        "For example, if we input **\\( x_1 = 5 \\), \\( x_2 = 6 \\)**, the predicted output should be approximately **33**.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "This simple **feedforward neural network** with multiple inputs demonstrates how a machine learning model learns relationships between variables. By adding more layers and neurons, we can build more complex models for real-world applications.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pi4MHT4JC0KY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6V3J5_l2Gnx",
        "outputId": "779da08b-95ca-4b1c-d9dc-b122b810a1b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (output): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.hidden = nn.Linear(2,3)\n",
        "    self.relu= nn.ReLU()\n",
        "    self.output=nn.Linear(3,1)\n",
        "  def forward(self,x):\n",
        "    x=self.hidden(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.output(x)\n",
        "    return x\n",
        "model=SimpleNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.MSELoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "BJLiTgcA7BKY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=torch.tensor([[1.0,2.0],[2.0,3.0],[3.0,4.0],[4.0,5.0]], dtype=torch.float32)\n",
        "y_train =torch.tensor([[13.0],[18.0],[23.0],[28.0]],dtype=torch.float32)\n",
        "\n",
        "for epoch in range(1000):\n",
        "  optimizer.zero_grad()\n",
        "  y_pred= model(x_train)\n",
        "  loss = criterion(y_pred,y_train)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch %10 ==0:\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im8hdtqR7P_d",
        "outputId": "7ee51fab-f37d-4ff7-e715-e6dee2a10e56"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 442.73223876953125\n",
            "Epoch 11, Loss: 130.52806091308594\n",
            "Epoch 21, Loss: 1.0528262853622437\n",
            "Epoch 31, Loss: 0.9646841883659363\n",
            "Epoch 41, Loss: 0.9307680130004883\n",
            "Epoch 51, Loss: 0.8979688286781311\n",
            "Epoch 61, Loss: 0.8662481307983398\n",
            "Epoch 71, Loss: 0.8355702757835388\n",
            "Epoch 81, Loss: 0.8059036135673523\n",
            "Epoch 91, Loss: 0.777215301990509\n",
            "Epoch 101, Loss: 0.7494755983352661\n",
            "Epoch 111, Loss: 0.7226531505584717\n",
            "Epoch 121, Loss: 0.6967184543609619\n",
            "Epoch 131, Loss: 0.6716446876525879\n",
            "Epoch 141, Loss: 0.6474071741104126\n",
            "Epoch 151, Loss: 0.6239761710166931\n",
            "Epoch 161, Loss: 0.6013281345367432\n",
            "Epoch 171, Loss: 0.579439103603363\n",
            "Epoch 181, Loss: 0.5582829117774963\n",
            "Epoch 191, Loss: 0.5378412008285522\n",
            "Epoch 201, Loss: 0.5180888772010803\n",
            "Epoch 211, Loss: 0.49900543689727783\n",
            "Epoch 221, Loss: 0.48057013750076294\n",
            "Epoch 231, Loss: 0.46276265382766724\n",
            "Epoch 241, Loss: 0.4455641508102417\n",
            "Epoch 251, Loss: 0.42895442247390747\n",
            "Epoch 261, Loss: 0.4129159152507782\n",
            "Epoch 271, Loss: 0.3974306881427765\n",
            "Epoch 281, Loss: 0.3824824392795563\n",
            "Epoch 291, Loss: 0.368053674697876\n",
            "Epoch 301, Loss: 0.3541271686553955\n",
            "Epoch 311, Loss: 0.3406883478164673\n",
            "Epoch 321, Loss: 0.3277209401130676\n",
            "Epoch 331, Loss: 0.3152100145816803\n",
            "Epoch 341, Loss: 0.3031421899795532\n",
            "Epoch 351, Loss: 0.29150187969207764\n",
            "Epoch 361, Loss: 0.2802750766277313\n",
            "Epoch 371, Loss: 0.2694514989852905\n",
            "Epoch 381, Loss: 0.25901633501052856\n",
            "Epoch 391, Loss: 0.24895595014095306\n",
            "Epoch 401, Loss: 0.23925942182540894\n",
            "Epoch 411, Loss: 0.22991448640823364\n",
            "Epoch 421, Loss: 0.2209102362394333\n",
            "Epoch 431, Loss: 0.21223445236682892\n",
            "Epoch 441, Loss: 0.2038774937391281\n",
            "Epoch 451, Loss: 0.19582784175872803\n",
            "Epoch 461, Loss: 0.18807452917099\n",
            "Epoch 471, Loss: 0.18060915172100067\n",
            "Epoch 481, Loss: 0.1734209954738617\n",
            "Epoch 491, Loss: 0.1665027141571045\n",
            "Epoch 501, Loss: 0.15984240174293518\n",
            "Epoch 511, Loss: 0.1534329354763031\n",
            "Epoch 521, Loss: 0.14726373553276062\n",
            "Epoch 531, Loss: 0.1413295865058899\n",
            "Epoch 541, Loss: 0.1356198489665985\n",
            "Epoch 551, Loss: 0.13012880086898804\n",
            "Epoch 561, Loss: 0.12484608590602875\n",
            "Epoch 571, Loss: 0.1197669506072998\n",
            "Epoch 581, Loss: 0.11488306522369385\n",
            "Epoch 591, Loss: 0.1101880669593811\n",
            "Epoch 601, Loss: 0.10567466169595718\n",
            "Epoch 611, Loss: 0.10133643448352814\n",
            "Epoch 621, Loss: 0.09716776013374329\n",
            "Epoch 631, Loss: 0.09316161274909973\n",
            "Epoch 641, Loss: 0.08931252360343933\n",
            "Epoch 651, Loss: 0.08561498671770096\n",
            "Epoch 661, Loss: 0.08206291496753693\n",
            "Epoch 671, Loss: 0.07865150272846222\n",
            "Epoch 681, Loss: 0.07537578046321869\n",
            "Epoch 691, Loss: 0.0722302496433258\n",
            "Epoch 701, Loss: 0.06921011209487915\n",
            "Epoch 711, Loss: 0.06631116569042206\n",
            "Epoch 721, Loss: 0.06352850049734116\n",
            "Epoch 731, Loss: 0.060856983065605164\n",
            "Epoch 741, Loss: 0.05829356610774994\n",
            "Epoch 751, Loss: 0.05583379417657852\n",
            "Epoch 761, Loss: 0.05347411334514618\n",
            "Epoch 771, Loss: 0.05120961368083954\n",
            "Epoch 781, Loss: 0.04903796315193176\n",
            "Epoch 791, Loss: 0.04695460945367813\n",
            "Epoch 801, Loss: 0.04495665803551674\n",
            "Epoch 811, Loss: 0.043041132390499115\n",
            "Epoch 821, Loss: 0.041203875094652176\n",
            "Epoch 831, Loss: 0.03944218158721924\n",
            "Epoch 841, Loss: 0.03775360435247421\n",
            "Epoch 851, Loss: 0.03613511845469475\n",
            "Epoch 861, Loss: 0.03458360210061073\n",
            "Epoch 871, Loss: 0.03309669345617294\n",
            "Epoch 881, Loss: 0.03167104348540306\n",
            "Epoch 891, Loss: 0.030305540189146996\n",
            "Epoch 901, Loss: 0.028997179120779037\n",
            "Epoch 911, Loss: 0.02774343453347683\n",
            "Epoch 921, Loss: 0.026542628183960915\n",
            "Epoch 931, Loss: 0.025392131879925728\n",
            "Epoch 941, Loss: 0.024289878085255623\n",
            "Epoch 951, Loss: 0.023234521970152855\n",
            "Epoch 961, Loss: 0.022223779931664467\n",
            "Epoch 971, Loss: 0.021255800500512123\n",
            "Epoch 981, Loss: 0.02032892219722271\n",
            "Epoch 991, Loss: 0.019441289827227592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = torch.tensor([[5.0,6.0]], dtype=torch.float32)\n",
        "y_pred = model(x_test)\n",
        "print(f\"Prediction for [5.0,6.0]: {y_pred.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4fYf6q077w5",
        "outputId": "e554b346-abda-4155-a5fc-6d19382a233c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for [5.0,6.0]: 33.24890899658203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5iRk2XbmB2Ak"
      }
    }
  ]
}